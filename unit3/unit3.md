# 3章　関数の最適化

- __最適化__ ... 与えられた制約条件のもとで関数の値の最大(最小)となる変数を求めること。

## 勾配法

関数の最適化方法として基礎的で単純だが強力。ニュートン法などの基となるのでここから紹介する。

基本的には、__与えられる関数 f'(x) = 0 は制約の中で f'(x)=0 となる x は1つしかない__ことが条件となる。勾配の方向に進んで行くのが最も関数の値を変化させるため、勾配の方向に1回で移動する幅(ステップ幅)を設定し、繰り返し更新を行っていく。また、関数f(x)とその導関数f'(x)が既知である必要がある。

### 1変数の場合

具体的な手順は以下の通りである。

***************

algorithm 1. １変数勾配法

*************************************************************************************************************************************************************************************************************************************************************************************************************************************************

1. xの初期値x0を与え、ステップ幅hをh0とする。

2. x, hを次のように更新する。
   $$
   h \larr sgn(f'(x))|h|,\ \ \ \  X \larr x, \ \ \ \ X' \larr x+h
   $$

3. もしf(X) < f(X')であれば次の計算を行う。

   - f(X) ≧ f(X')となるまで次の計算を行う。
     $$
     h \larr 2h,\ \ \ X \larr X', \ \ \ X' \larr X+h
     $$

   - f(X) < f(X')となったら次を行う。
     $$
     x \larr X, \ \ \ h \larr \frac{h}{2}
     $$

4. そうでなければ次の計算を行う。

   - f(X) ≦ f(X')となるまで次を行う。
     $$
     h \larr \frac{h}{2}, \ \ \ X' \larr X' \ h
     $$

   - f(X) > f(X')となったら次を行う。
     $$
     x \larr X, \ \ \ h \larr 2h
     $$

5. ステップ2に戻り、これを |f'(x)| ≦ |ε| になるまで繰り返す。(εは許容誤差)

6. 以上より得られたxを返す。

****************

*************************************************************************************************************************************************************************************************************************************************************************************************************************************************

勾配法はコンピュータで行う都合上、解析的に解いた場合と比べて誤差がある程度出てしまうのは仕方がないので、ステップ5で行うような収束判定が必要である。また、初期値の与え方次第で収束にかかる時間がかなり変わるらしいので、適切な初期値の与え方、すなわち最適解のそばっぽいところを選んで初期値とするのが良いらしい。詳しく説明できるほど理解できていないので、理解できたら追記する。

### 多変数の場合

多変数の場合も1変数と変わらず勾配∇f(x)が最も関数値を変化させるので、勾配∇fを与えてその直線方向で最大値になる点を探索する(直線探索)。探索の方法は1変数の場合と変わらないが、アルゴリズムを以下に示す。

******************

algorithm 2. 多変数勾配法

*******

1. __x__ に初期値を与える。
2. 関数F(__x__) = f( __x__ + t∇f(__x__) )に対してalgorithm 1 を行い、直線探索を行う。
3. algorithm 1に返される t を用いて次の更新を行う。

$$
\Delta \bold{x} \larr t \nabla f(\bold{x}), \ \ \ \bold{x} \larr \bold{x} + \Delta \bold{x}
$$

4. ステップ2に戻り、これを||Δ__x__|| < δ となるまで繰り返す。
5. 得られた__x__ を返す。

******

****

ステップ2で必要となるのが、F(__x__)の導関数F'(__x__)なので、これを求める。__x__ = __x0__ + t ∇f0 とおいてF(t) = f(__x__(t)) をt で微分すると次のようになる。(自分用メモ：__x__がtの関数になっている)
$$
\frac{dF}{dt} = \sum^{n}_{i=1}\frac{\partial f}{\partial x_i} \frac{dx_i}{dt} = \sum^{n}_{i=1}\frac{\partial f}{\partial x_i} \frac{\partial f_0}{\partial x_i} = \nabla f \cdot{\nabla f_0}
$$
このF(t)が極値を取る、すなわち 
$$
\frac{dF}{dt} = \nabla f \cdot \nabla f_0 = 0
$$
となるので、探索直線∇f0 と極値を取る点__x__ での勾配∇f は直行することがわかる。 これは、初期値に基づく探索直線(1)で得られた値を再び初期値として探索直線(2)がある時、これらは直行するということを示している。

このこと自体に意味はないが、関数を等高線表示した場合に勾配法がどのように更新しているのかがわかりやすくなるので嬉しい。

### 勾配法の問題点

斯様にして万能にも思える勾配法だが、以下のような欠点がある。

1. アルゴリズム内に必ず勾配∇f が必要になるため、不連続であったり解析的に勾配が計算できない場合は適用できない。
2. 局所解から抜ける気がないので、関数の形次第で初期値の与え方で収束する値が異なる可能性がある。
3. 極値付近の形状次第で収束に時間がかかることがある。



## ニュートン法

f(__x__)について2階の導関数まで求められる場合、より効率的な__ニュートン法__を適用することができる。多分世の中の人はコンピュータで関数近似をする際に最初に勉強するのはこれ。f'(x) = 0となるxが最大になるのでうれしいよねということを考える。

### 1変数の場合

1変数関数f(x)をテイラ展開するとこんな感じになる。
$$
f(\bar{x}+\Delta x) = f(\bar{x}) + f'(\bar{x})\Delta x + \frac{1}{2}f''(\bar{x})\Delta x^2 + ...
$$
ここで右辺の3次以上の高次の項を無視して放物線として考える。左辺が最大になるΔxを求めるならば、次を考える。
$$
f'(\bar{x}) + f''(\bar{x})\Delta x = 0
$$

$$
\Delta x = - \frac{f'(\bar{x})}{f''(\bar{x})}
$$

このΔxを用いて、最適解xのより良い近似値は次のようになる。
$$
x = \bar{x} - \frac{f'(\bar{x})}{f''(\bar{x})}
$$
これを反復していくことで最適解x* を求める。以下にアルゴリズムをまとめる。

*****************

algorithm 3. 1変数ニュートン法

**************

1. 初期値xを与える。
2. 次のようにxを更新する。

$$
\bar{x} \larr x
$$

$$
x \larr \bar{x} - \frac{f'(\bar{x})}{f''(\bar{x})}
$$

$$
(x \larr \bar{x} + \Delta x)
$$

3. ステップ2に戻り、これを|x - x~| < δ となるまで繰り返す。

4. 得られたxを返す。

********

******

とてもわかり易く、かつ強力な手法に感じますね。

- 例題

  以下の関数について次の問に答えよ。
  $$
  f(x) = x^3 - 2x^2 + x + 3
  $$
  

  1. x = 2 における2次近似f2(x) を求めよ。
  2. f2(x)が極値を取る点を求めよ。
  3. f(x)にニュートン法を適用する際の更新式を求めよ。

- 解答

  1.  f'(x), f''(x) を求める。

  $$
  f'(x) = 3x^2 - 4x + 1,\ \ \ \ \ f''(x) = 6x - 4
  $$

  ​		x = 2を代入して、
  $$
  f(2) = 5,\ \  f'(2) = 5,\ \  f''(x) = 8
  $$
  ​		したがって、２次近似は、
  $$
  f_2(x) = 5 + 5(x-2) + 4(x-2)^2
  $$
  
2. f2(x)の勾配が0となるxを求めれば良いので、
  
$$
  f_2'(x) = 5 + 8(x-2) = 0
  $$
  
$$
  x = \frac{11}{8}
  $$
  
3. f(x)の２次近似は以下のように定義される。
  
$$
  x = \bar{x}のとき、
  $$
  
$$
  f_2(\bar{x}) = f(\bar{x}) + (3\bar{x}^2 - 4\bar{x} + 1)(x - \bar{x}) + \frac{1}{2}(6\bar{x} - 4)(x - \bar{x})^2
  $$
  
​		この導関数は次のようになる。
  $$
  f_2'(x) = 3\bar{x}^2 - 4\bar{x} + 1 + (6\bar{x} - 4)(x - \bar{x})
  $$
  ​		これを0とおいてx-x~について解くと、
  $$
  x - \bar{x} = - \frac{3\bar{x}^2 - 4\bar{x} + 1}{6\bar{x} - 4}
  $$
  ​		したがって、次の更新が誤差範囲が許容誤差未満になるまで反復すればよい。
  $$
  x \larr \bar{x} - \frac{3\bar{x}^2 - 4\bar{x} + 1}{6\bar{x} - 4}
  $$
  

テイラ展開した時に、(x-x~)の項を展開しないで計算するというのが大事っぽい。何も知らなかったら脳死で展開してそうなので。



### 多変数の場合

１変数と同様にテイラ展開します。多変数のテイラ展開は辛い…。
$$
f(\bar{x_1} + \Delta x_1,...,\bar{x_n} + \Delta x_n) = \bar{f} + \sum^{n}_{i=1}\frac{\partial \bar{f}}{\partial x_i} \Delta x_i + \frac{1}{2}\sum^n_{i=1}\sum^{n}_{j=1}\frac{\partial^2 \bar{f}}{\partial x_i \partial x_j}\Delta x_i \Delta x_j + R(x_1,\ ...\ ,x_n)
$$
高次の項を無視して、Δx_i で微分したものを0と置くと、次のように書ける。
$$
\frac{\partial \bar{f}}{\partial x_i} + \sum^{n}_{j=1}\frac{\partial^2 \bar{f}}{\partial x_i \partial x_j}\Delta x_j = 0
$$
ここで、ヘッセ行列__H__を次のように定義する。
$$
\large
\bold{H} = \Biggl( \matrix {
\frac{\partial^2f}{\partial x_1^2} & \cdots & \frac{\partial^2f}{\partial x_1 \partial x_n}\\
\vdots & \ddots & \vdots\\
\frac{\partial^2f}{\partial x_n \partial x_1} & \cdots & \frac{\partial^2f}{\partial x_n^2}\\
}\Biggr)
$$


これを用いてテイラ展開した式を表すと、
$$
\bold{\bar{H}} \Delta \bold{x} = - \nabla \bar{f}
$$
となる。したがって解は次のようになる。
$$
\Delta \bold{x} = - \bold{\bar{H}^{-1}} \nabla \bar{f}
$$
よって、より良い近似解に更新するには次式を行う。
$$
\bold{x} \larr \bold{\bar{x}} - \bold{\bar{H} ^ {-1}} \nabla\bar{f}
$$
アルゴリズムをまとめる。

****

algorithm 4. 多変数ニュートン法

**********

1.  __x__の初期値を与える。
2. 勾配∇fとヘッセ行列__H__の__x__における値を計算する。
3. 次の計算を行う。

$$
\bold{H} \Delta \bold{x} = - \nabla f
$$

4.  __x__について次の更新を行う。

$$
\bold{x} \larr \bold{x} + \Delta \bold{x}
$$

$$
(\bold{x} \larr \bold{x} - \bold{H}^{-1}\nabla f)
$$

5. ||__Δx__|| < δ となるまでステップ２に戻る。
6. __x__ を返す。

*******

******

例題は行列書くのがつらいので割愛。

ニュートン法について、以下のメリット/デメリットがある。

- メリット
  
- 勾配法と比べて収束する速度が非常にはやい
  
- デメリット

  - ヘッセ行列を計算するために二階の導関数までは解析的に求める必要があるので、複雑な形での実装は困難

  - 更新にヘッセ行列の逆行列を計算する必要があるが、[逆行列の計算量はO(N^3)らしい](http://fast-programming.aglk.net/matrix-calculation/index.php)ので、変数の数の3乗に比例して計算量が大きくなる。あまり多変数の関数には適用できない。

  - 極値が複数あるような関数だと初期値から近い方の極値に行く(仕組み上しょうがない？)

    ![order_N3](./order_N3.png)
  

(ヘッセ行列は各自調べておくこと。自分もよくわからないので完全理解したら誰か教えてほしい。)

以上でニュートン法の説明を終わる。端的に言ってしまえばテイラ展開で２次までの項を計算できればニュートン法は実装することができる。複雑な形をした関数でもテイラ展開して二次関数に近似してしまえば最適解が求まるという考え方だと理解している。



### 注意！！！

今回説明したニュートン方は極値を求める時のニュートン法です。一般的にはニュートン法はf(x) = 0となるxを求める方法っぽく、これを求める場合には一階微分とf(x)がわかっていれば以下のように更新していくことでxが求められるっぽいです。
$$
x \larr x - \frac{f(x)}{f'(x)}
$$
詳しくは[こちら](https://qiita.com/PlanetMeron/items/09d7eb204868e1a49f49)を参照されたし。